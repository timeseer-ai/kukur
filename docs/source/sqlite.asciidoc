// SPDX-FileCopyrightText: 2022 Timeseer.AI
// SPDX-License-Identifier: Apache-2.0

== SQLite

Sources with `type = "sqlite"` configure SQLite sources.

The connection string and queries can either be configured in the configuration file,
or loaded from files.
Inline configuration takes precedence over file-based configuration when both are provided.

```toml
[source.<name>]
type = "sqlite"
connection_string = "<SQLite connection_string>"
connection_string_path = "<path to connection string>"
query_timeout_seconds = 0
list_query = "<query to list all time series in a source>"
list_query_path = "<path to list_query>"
list_columns = ["<metadata type of column 1>", "<metadata type of column 2"]
tag_columns = ["series name"]
field_columns = []
metadata_query = "<query for metadata of one series>"
metadata_query_path = "<path to metadata query>"
metadata_columns = ["<metadata type of column 1>", "<metadata type of column 2"]
dictionary_query = "<query for dictionary mappings>"
dictionary_query_path = "<path to the dictionary query>"
metadata_value_mapping = "<metadata_value_mapping name>"
data_query = "<query for data of one series in time range>"
data_query_path = "<path to data query>"
data_query_datetime_format = "<strftime format>"
data_query_timezone = "<override or specify time zone of timestamps>"
data_timezone = "<override or specify time zone of timestamps returned by the data query>"
enable_trace_logging = false
quality_mapping = "<name>"
```

The examples given here operate on a SQLite database with three tables:

```
create table Metadata (
    id integer primary key autoincrement,
    name text not null,
    description text,
    units text,
    interpolationType text,
    dataType text,
    dictionaryName text
);

create table Dictionary (
    id integer primary key autoincrement,
    name text not null,
    value real not null,
    label text not null
);

create table Data (
    id integer primary key autoincrement,
    name text not null,
    ts datetime not null,
    value real
);

```

=== Connection

The `connection_string` contains either the SQLite database file name or the URI to the database.

```toml
connection_string = "data/db.sqlite"
```

Alternatively, `connection_string_path` can point to a file that contains the connection string.
Whitespace at the start and end of the connection string file is removed.

`query_timeout_seconds` defines the timeout on a query.
Default is 0,
no timeout.

=== Search

The `list_query` is optional.
It returns a list of time series names found in the source.
When provided, it does not need a series to have been used in another context before it can be analyzed.

```toml
list_query = "select name from Metadata"
```

The query can be read from a file by using `list_query_path` instead of `list_query`.

The query can either return only series names or all metadata.
When it returns all metadata, include a `list_columns` entry that describes all columns:

```toml
list_query = "select name, description, units, interpolationType, dataType, dictionaryName from Metadata"
list_columns = ["series name", "description", "unit", "interpolation type", "data type", "dictionary name"]
```

All columns defined in `tag_columns` should be included in `list_columns`.
All combinations of rows returned by the `list_query` and values in `field_columns`
define a series.

Built-in metadata columns are:

- `series name` (required)
include::{include-path}/metadata-fields.asciidoc[]

Custom metadata fields can be defined by including them in the `list_columns` list.

Not all SQLite sources can map metadata field values to the values expected by Kukur.
Use `metadata_value_mapping` to convert them.

Example:

```toml
[source.<name>]
metadata_value_mapping = "sqlite_lowercase"

[metadata_value_mapping.sqlite_lowercase."data type"]
FLOAT64 = "float64"
STRING = ["string", "text", "varchar"]
DICTIONARY = "dictionary"
```

This example converts lowercase data types to the uppercase strings expected by Kukur.

=== Metadata

The `metadata_query` is a query that accepts one parameter for each tag in a series,
ordered by `tag_columns`.

```toml
metadata_query = "select description, units, interpolationType, dataType, dictionaryName from Metadata where name = ?"
```

The columns in the result set should be mapped to a supported type of metadata.
The `metadata_columns` entry contains a list with the positional mapping.

```toml
metadata_columns = ["description", "unit", "interpolation type", "data type", "dictionary name"]
```

Built-in types of metadata are:

include::{include-path}/metadata-fields.asciidoc[]

Custom metadata fields can be defined by including them in the `metadata_columns` list.

The metadata query can be read from a file by using `metadata_query_path` instead of `metadata_query`.

Metadata values can be converted using `metadata_value_mapping`.

Example:

```toml
[source.<name>]
metadata_value_mapping = "sqlite_lowercase"

[metadata_value_mapping.sqlite_lowercase."data type"]
FLOAT64 = "float64"
STRING = ["string", "text", "varchar"]
DICTIONARY = "dictionary"
```

This example converts lowercase data types to the uppercase strings expected by Kukur.

Kukur supports the SQLite https://www.sqlite.org/lang_expr.html#the_like_glob_regexp_match_and_extract_operators[`MATCH`] operator.

Consider the following table that contains additional metadata about a sensor vendor per location:

```
create table Sensors (
    id integer primary key autoincrement,
    location text not null,
    vendor text not null
);
```

If the location is part of the series name,
the following query will return the sensor vendor:

```sql
select vendor from Sensors where location = (? match 'location=([^,]+)')
```

If the configuration defines `tag_columns`,
they are provided in the same order as defined in `tag_columns`.

```toml
[source.<name>]
tag_columns = ["location", "plant"]
```

```toml
metadata_query = """
select description, units, interpolationType, dataType, dictionaryName
from Metadata
where my_location = ? and my_plant = ?
"""
```

=== Dictionary

A dictionary maps numerical (integer) values to textual labels.
The `dictionary query` is a query that accepts one parameter: the name of the dictionary.

The dictionary name for a series is returned by the `dictionary name` list or metadata column.

```toml
dictionary_query = "select value, label from Dictionary where name = ?"
```

The query should return rows of two columns:

- the numerical value that occurs in the data, in a type that can be converted to an integer
- the label for the numerical value

The dictionary query can be read from a file by using `dictionary_query_path` instead of `dictionary_query`.

=== Data

The `data_query` is a query that accepts three parameters:

- the name of the series
- the start date of the time range to query data
- the end date of the time range to query data

```toml
data_query = "select ts, value from Data where name = ? and ts >= ? and ts < ?"
```

This query should return rows of two columns:

- the timestamp of the data point
- the value of the data point

It will try to convert columns to the expected type.

The data query can be read from a file by using `data_query_path` instead of `data_query`.

Kukur expects a table to contain ISO8601 formatted timestamps.

Alternatively, the start and end date can be formatted as a string.
The `data_query_datetime_format` option accepts the https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior[formatting options] supported by Python.

Example:

```toml
data_query_datetime_format = "%Y-%m-%dT%H:%M:%S%z"
```

This converts timestamps to the ISO8601 format.

If the table doesn't store timezoned timestamps you can specify the prefered timestamp for the input to convert the timestamp with the `data_query_timezone` option.
The request will use the converted timestamps as naive timestamps for the queries.

Example:

```toml
data_query_timezone = "UTC"
```

If the query returns dates without a time zone,
the time zone can be specified by the `data_timezone` option.

Example:

```toml
data_timezone = "UTC"
```

The exact available time zones are system-dependent.

Set `enable_trace_logging` to `true` to log the fetched data before conversion.

```toml
enable_trace_logging = true
```

If the configuration defines `tag_columns`,
they are provided in the same order as defined in `tag_columns`.

```toml
[source.<name>]
tag_columns = ["location", "plant"]
```

```toml
data_query = """
select ts, value
from Data
where my_location = ? and my_plant = ? and ts >= ? and ts < ?
"""
```

If the configuration defines `field_columns`,
the field is available as `{field}` in the `data_query`.

```toml
[source.<name>]
field_columns = ["temperature", "pressure"]
```

```toml
data_query = """
select ts, {field},
from Data
where name = ? and ts >= ? and ts < ?
"""
```

=== Quality

There is a possibility to add a quality column.

In this case the data query changes:

```toml
data_query = "select timestamp, value, quality from Data where name = ? and ts >= ? and ts < ?"
```

Where `quality` represents the column that contains the data point quality.

Check the
ifdef::sources[]
<<Quality, source documentation>>
endif::sources[]
ifndef::sources[]
link:sources.asciidoc#Quality[source documentation]
endif::sources[]
to configure the mapping of a value in the quality column to a quality status known to Kukur.
