// SPDX-FileCopyrightText: 2021 Timeseer.AI
//
// SPDX-License-Identifier: Apache-2.0
== ODBC

Sources with `type = "odbc"` configure ODBC sources.

The connection string and queries can either be configured in the configuration file,
or loaded from files.
Inline configuration takes precedence over file-based configuration when both are provided.

```toml
[source.<name>]
type = "odbc"
connection_string = "<ODBC connection_string>"
connection_string_path = "<path to connection string>"
query_timeout_seconds = 0
query_timeout_enable = true
query_string_parameters = false
list_query = "<query to list all time series in a source>"
list_query_path = "<path to list_query>"
list_columns = ["<metadata type of column 1>", "<metadata type of column 2"]
tag_columns = ["series name"]
field_columns = []
metadata_query = "<query for metadata of one series>"
metadata_query_path = "<path to metadata query>"
metadata_columns = ["<metadata type of column 1>", "<metadata type of column 2"]
dictionary_query = "<query for a possible dictionary mapping>"
dictionary_query_path = "<path to a dictionary query>"
metadata_value_mapping = "<metadata_value_mapping name>"
data_query = "<query for data of one series in time range>"
data_query_path = "<path to data query>"
data_query_timezone = "<override or specify time zone of timestamps to send a naive timestamp to the odbc driver>"
data_timezone = "<override or specify time zone of timestamps returned by the odbc driver>"
enable_trace_logging = false
quality_mapping = "<name>"
type_checking_row_limit = 300  # number of rows analysed to determine the type of the value column
```

The examples given here operate on this schema:

```sql
create table Metadata (
    name nvarchar(max),
    description nvarchar(max),
    units nvarchar(max),
    dictionary_name nvarchar(max)
);

create table Dictionary (
    name nvarchar(max),
    value int,
    label nvarchar(max)
);

create table Data (
    name nvarchar(max),
    ts datetime2,
    value float(53),
);
```

=== Connection

The `connection_string` can point to a DSN or be a direct driver connection.

```toml
connection_string = "DSN=kukur;UID=sa;PWD=Kukur!AI"
```

or

```toml
connection_string = "Driver={/usr/lib/libtdsodbc.so};Server=localhost;Port=1433;Database=TestData;UID=sa;PWD=Kukur!AI"
```

Alternatively, `connection_string_path` can point to a file that contains the connection string.
Whitespace at the start and end of the connection string file is removed.

Some ODBC drivers do not support parameter binding.
Set `query_string_parameters` to `true`,
to use string interpolation of parameters in queries.

In that case use `{}` to format parameters into queries.
In queries with multiple parameters, the order can be changed by using the argument position: `{1} {2} {0}`.
Use a read-only connection with a minimal amount of privileges as https://owasp.org/www-community/attacks/SQL_Injection[SQL Injection] are possible in that case and cannot be prevented by Kukur.


`query_timeout_seconds` defines the timeout on a query.
Default is 0,
no timeout.

Some drivers do not allow setting a timeout.
Disable it using `query_timeout_enable = false`.

=== Search

The `list_query` is optional.
It returns a list of time series names found in the source.
When provided, it does not need a series to have been used in another context before it can be analyzed.

```toml
list_query = "select name from Metadata"
```

The query can be read from a file by using `list_query_path` instead of `list_query`.

The query can either return only series names or all metadata.
When it returns all metadata, include a `list_columns` entry that describes all columns:

```toml
list_query = "select name, description, units from Metadata"
list_columns = ["series name", "description", "unit"]
```

All columns defined in `tag_columns` should be included in `list_columns`.
All combinations of rows returned by the `list_query` and values in `field_columns`
define a series.

Built-in columns are:

- `series name` (required)
include::{include-path}/metadata-fields.asciidoc[]

Custom metadata fields can be defined by including them in the `list_columns` list.

Not all ODBC sources can map metadata field values to the values expected by Kukur.
Use `metadata_value_mapping` to convert them.

Example:

```toml
[source.<name>]
metadata_value_mapping = "odbc_lowercase"

[metadata_value_mapping.odbc_lowercase."data type"]
FLOAT64 = "float64"
STRING = ["string", "text", "varchar"]
DICTIONARY = "dictionary"
```

This example converts lowercase data types to the uppercase strings expected by Kukur.

=== Metadata

The `metadata_query` is a query that accepts one parameter for each tag in a series,
ordered by `tag_columns`.

```toml
metadata_query = "select description, units from Metadata where name = ?"
```

The columns in the result set should be mapped to a supported type of metadata.
The `metadata_columns` entry contains a list with the positional mapping.

```toml
metadata_columns = ["description", "unit"]
```

Supported types of metadata are:

include::{include-path}/metadata-fields.asciidoc[]

Custom metadata fields can be defined by including them in the `metadata_columns` list.

The metadata query can be read from a file by using `metadata_query_path` instead of `metadata_query`.

Metadata values can be converted using `metadata_value_mapping`.

Example:

```toml
[source.<name>]
metadata_value_mapping = "odbc_lowercase"

[metadata_value_mapping.odbc_lowercase."data type"]
FLOAT64 = "float64"
STRING = ["string", "text", "varchar"]
DICTIONARY = "dictionary"
```

This example converts lowercase data types to the uppercase strings expected by Kukur.

If the configuration defines `tag_columns`,
they are provided in the same order as defined in `tag_columns`.

```toml
[source.<name>]
tag_columns = ["location", "plant"]
```

```toml
metadata_query = """
select description, units, interpolationType, dataType, dictionaryName
from Metadata
where my_location = ? and my_plant = ?
"""
```

=== Dictionary

A dictionary maps numerical (integer) values to textual labels.
The `dictionary_query` is a query that accepts one parameter: the name of the dictionary.

The dictionary name for a series is returned by the `dictionary name` list or metadata column.

```toml
dictionary_query = "select value, label from Dictionary where name = ?"
```

The first column with the dictionary key can be any type that can be converted to an integer, even `SQL_CHAR`.
The second column with the dictionary value should be a `SQL_CHAR` or `SQL_WCHAR`.

The dictionary query can be read from a file by using `dictionary_query_path` instead of `dictionary_query`.

=== Data

The `data_query` is a query that accepts three parameters:

- the name of the series (as `SQL_VARCHAR`)
- the start date of the time range to query data in (as `SQL_TYPE_TIMESTAMP`)
- the end date of the time range to query data in (as `SQL_TYPE_TIMESTAMP`)

```toml
data_query = "select ts, value from Data where name = ? and ts between ? and ?"
```

This query should return rows of two columns:

- the timestamp of the data point (preferably as `SQL_TYPE_TIMESTAMP`)
- the value of the data point (preferably as `SQL_REAL`, `SQL_FLOAT` or `SQL_DOUBLE`)

When the return type of a column is of types `SQL_CHAR` or `SQL_WCHAR`,
It will try to convert to the expected type.

If the provider or data source does not accept `SQL_TYPE_TIMESTAMP`, it can be formatted as a string.
The `data_query_datetime_format` option accepts the https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior[formatting options] supported by Python.

Example:

```toml
data_query_datetime_format = "%Y-%m-%dT%H:%M:%S%z"
```

This converts timestamps to the ISO8601 format.

The data query can be read from a file by using `data_query_path` instead of `data_query`.

If the driver doesn't accept timezoned timestamps you can specify the prefered timestamp for the input to convert the timestamp with the `data_query_timezone` option.
The request will use the converted timestamps as naive timestamps for the queries to the driver.

Example:

```toml
data_query_timezone = "UTC"
```

If the query or driver returns dates without a time zone,
the time zone can be specified by the `data_timezone` option.

Example:

```toml
data_timezone = "UTC"
```

The exact available time zones are system-dependent.

Set `enable_trace_logging` to `true` to log the fetched data before conversion.

```toml
enable_trace_logging = true
```

If the configuration defines `tag_columns`,
they are provided in the same order as defined in `tag_columns`.

```toml
[source.<name>]
tag_columns = ["location", "plant"]
```

```toml
data_query = """
select ts, value
from Data
where my_location = ? and my_plant = ? and ts >= ? and ts < ?
"""
```

If the configuration defines `field_columns`,
the field is available as `{field}` in the `data_query`.

```toml
[source.<name>]
field_columns = ["temperature", "pressure"]
```

```toml
data_query = """
select ts, {field},
from Data
where name = ? and ts >= ? and ts < ?
"""
```

=== Quality

There is a possibility to add a quality column.

In this case the data query changes:

```toml
data_query = "select ts, value, quality from Data where name = ? and ts between ? and ?"
```

Where `quality` represents the column that contains the data point quality of the ODBC source.

Check the
ifdef::sources[]
<<Quality, source documentation>>
endif::sources[]
ifndef::sources[]
link:sources.asciidoc#Quality[source documentation]
endif::sources[]
to configure the mapping of a value in the quality column to a quality status known to Kukur.
