// SPDX-FileCopyrightText: 2021 Timeseer.AI
//
// SPDX-License-Identifier: Apache-2.0
== Apache Parquet

Sources with `type = "parquet"` configure http://parquet.apache.org/[Apache Parquet] sources.

Parquet supports the same source layouts as CSV:

```
[source.<name>]
type = "parquet"
format = "row|dir|pivot"
path = "<path to data>"
quality_mapping = "<name>"
```

`path` is required.

`format` defaults to `"row"`.

Metadata in Parquet is not supported.
Use a different `metadata_type` to connect to metadata.

For example:

```toml
metadata_type = "csv"
```

=== Column mapping

Accepted by Apache Parquet sources that use the row based or directory based
data models.
This configuration allows mapping the columns of tables read from parquet
files to the columns expected by Kukur.
This is done by setting the `column_mapping` option for the source.

```toml
[source.<name>.column_mapping]
"series name" = "name"
"ts" = "timestamp"
"value" = "value"
"quality" = "quality column"
```

`series name` is only valid for the `row` format,
as the directory data model uses the parquet file names as the series names.

`quality` mapping is optional.

=== Row format

```toml
format = "row"
```

The row based format expects `path` to be a Parquet file with at least 3 columns:

- The first column contains the `series name` as a string
- The second column contains the timestamp
- The third column contains the value as a numerical type or a string

=== Directory Based Format

```toml
format = "dir"
```

The directory based format expects `path` to be a directory containing Parquet files.
Each file inside `path` is named `<series name>.parquet`.

The Parquet file contains at least 2 columns:

- The first column contains the timestamp
- The second column contains the value as a numerical type or a string

=== Pivot Format

```toml
format = "pivot"
```

The pivot format expects `path` to be a Parquet file.

The first column in the file is a timestamp.
Further columns contain the values.
Some columns can be numerical while other columns contain strings.
The name of each column is the series name.

=== Quality

There is a possibility to add a quality column in the Parquet file.
Check the
ifdef::sources[]
<<Quality, source documentation>>
endif::sources[]
ifndef::sources[]
link:sources.asciidoc#Quality[source documentation]
endif::sources[]
to configure the mapping of a value in the quality column to a quality status known to Kukur.

A quality column is not available for a Parquet file with a pivot data format.

=== Azure Blob Storage

Kukur can load Parquet files from Azure Blob Storage.
This requires the https://pypi.org/project/azure-storage-blob/[azure-storage-blob] and https://pypi.org/project/azure-identity/[azure-identity] Python packages.

The following

[source,toml]
----
[source."My Azure Source"]
...
loader = "azure-blob"
azure_connection_string = "DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=<storage account name>"
azure_container = "<container name>"
azure_identity = "default"
----

Paths provided to `path` will be relative to the container root.

The `azure_identity` field is optional.
The special value `default` causes connections to be made using the https://docs.microsoft.com/en-us/python/api/overview/azure/identity-readme?view=azure-python[default Azure credentials].
This is the only supported value and allows connections using a managed service identity.

When the `azure_identity` field is omitted,
the `azure_connection_string` needs to contain the necessary secrets (SAS token, Access key).
