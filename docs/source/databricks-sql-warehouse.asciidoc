== Databricks SQL Warehouse

Connections to a https://www.databricks.com/product/databricks-sql[Databricks SQL warehouse] use the https://docs.databricks.com/en/integrations/odbc/index.html[Databricks ODBC Driver].
The driver is included in the container image,
but needs to be installed separately in other deployments.

All connection options supported in the
ifdef::sources[]
<<ODBC, ODBC source>>
endif::sources[]
ifndef::sources[]
link:odbc.asciidoc[ODBC source]
endif::sources[]
are supported by the `databricks-sql` source.
The `odbc` source could be used instead,
but the `databricks-sql` source provides more convenience by pre-configuring various connection settings.

Authentication methods supported out-of-the-box are:

* Databricks personal access token
* OAuth machine-to-machine authentication
* Azure managed identities authentication

Other authentication methods are supported by configuring a `connection_string` with the required https://learn.microsoft.com/en-us/azure/databricks/integrations/odbc/authentication[authentication options].

```toml
[source.Databricks]
type = "databricks-sql"
...

[source.Databricks.connection]
driver = "/opt/simba/spark/lib/64/libsparkodbc_sb64.so"
host = ""
port = 443
http_path = ""
Azure_workspace_resource_id = "" # Optional, only required for authentication using managed identities.
oauth_client_id = "" # Optional, only required for OAuth authentication.
oauth_secret = "" # Optional, only required for OAuth authentication.
password = "" # Optional, only required for personal access token authentication.
```

The example configuration below connects the `tsaideltalake.poc.tsai_antwerp` table using OAuth M2M authentication.

First follow the steps in the https://learn.microsoft.com/en-us/azure/databricks/integrations/odbc/authentication#authentication-m2m[OAuth machine-to-machine authentication documentation].

Then,
open the SQL Warehouse in the Databricks Workspace.
Go to `Connection details`.

Copy the `Server hostname` and the `HTTP path`.

```toml
[source.Databricks]
type = "databricks-sql"
list_query = """
select distinct `series name` from tsdeltalake.poc.tsai_antwerp
"""
list_columns = ["series name"]
data_query = """
select ts, value
from tsdeltalake.poc.tsai_antwerp
where `series name` = ?
  and ts >= ?
  and ts < ?
"""

[source.Databricks.connection]
host = "adb-5136731089164599.19.azuredatabricks.net"
http_path = "/sql/1.0/warehouses/2cf2d4cd375bb81a"
oauth_client_id = "5edbb8d4-9ec4-4313-99bb-28a18982f339"
oauth_secret = "verysecuresecret"
```

=== Connecting to Databricks SQL Warehouses on Azure using Managed Identities

On Azure,
using Managed Identities is the preferred authentication method since it avoids having to use and manage secrets.

The Managed Identity of the VM needs to be defined as a Service Principal in Databricks.

The full documentation to achieve this is available at https://learn.microsoft.com/en-us/azure/databricks/dev-tools/azure-mi-auth[Set up and use Azure managed identities authentication for Azure Databricks automation]

The required steps are:

- Go to the VM in the Azure portal. Copy the `Object ID` of the VM Identity.
- Go to Entra ID. Search for the `Object ID` copied in the previous step. Copy the `Application ID`.
- Go to the https://accounts.azuredatabricks.net/[Databricks Account console].
- In `User management` - `Service principals`, choose `Add service principal`.
- Choose `Microsoft Entra ID managed`. Paste the `Application ID`. Give the service principal a name.
- Go to `SQL Warehouses` in the Databricks Workspace. Add `Can use` permissions to the service principal.
- In the `Catalog`, grant `Data Reader` permissions to the service principal.

```toml
[source.Databricks.connection]
host = "adb-5136731089164599.19.azuredatabricks.net"
http_path = "/sql/1.0/warehouses/2cf2d4cd375bb81a"
Azure_workspace_resource_id = "/subscriptions/4eaf5c02-76be-4f45-b92a-d5882e686c95/resourceGroups/rg-kukur/providers/Microsoft.Databricks/workspaces/kukur-demo"
```

=== Connecting to Databricks SQL Warehouses using a Personal Access Token

Generate a personal access token in 'Settings' - 'Developer' - 'Access tokens'.
This token will have your permissions.
Do not use this except for testing or local work.

```toml
[source.Databricks.connection]
host = "adb-5136731089164599.19.azuredatabricks.net"
http_path = "/sql/1.0/warehouses/2cf2d4cd375bb81a"
password = "verysecuresecret"
```

=== Using Alternative Authentication Options

Refer to https://learn.microsoft.com/en-us/azure/databricks/integrations/odbc/authentication[Authentication settings for the Databricks ODBC Driver] for alternative authentication options.

The `connection_string` can be passed as one string:

```toml
[source.Databricks]
connection_string = """
Driver=/opt/simba/spark/lib/64/libsparkodbc_sb64.so;
Host=adb-5136731089164599.19.azuredatabricks.net;
Port=443;
HTTPPath=/sql/1.0/warehouses/2cf2d4cd375bb81a;
SSL=1;
ThriftTransport=2;
AuthMech=11;
Auth_Flow=3;
Azure_workspace_resource_id=/subscriptions/4eaf5c02-76be-4f45-b92a-d5882e686c95/resourceGroups/rg-kukur/providers/Microsoft.Databricks/workspaces/kukur-demo;
"""
```
